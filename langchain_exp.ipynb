{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API credentials\n",
    "with open('api_key.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "os.environ['OPENAI_API_KEY'] = config['OPEN_AI_KEY']\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = config['HUGGING_FACE_TOKEN_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "### - Models\n",
    "    - LLMs: 20+ integrations models\n",
    "    - Chat Models\n",
    "    - Text Embedding models: 10+ integrations\n",
    "\n",
    "### - Prompts\n",
    "    - Prompt Templates\n",
    "    - Output Parsers: 5+ implementations\n",
    "        - Retry/fixing logic\n",
    "    - Example Selectors: 5+ implementations\n",
    "\n",
    "### - Indexes\n",
    "    - Document Loaders: 50+ implementations\n",
    "    - Text Splitters: 10+ implementations\n",
    "    - Vector stores\n",
    "    - Retrievers\n",
    "\n",
    "### - Chains\n",
    "    - Prompt + LLM + Output parsing\n",
    "    - Can be used as building blocks for longer chains\n",
    "    - More application specific chains: 20 + types\n",
    "\n",
    "### - Agents\n",
    "    - Agent types: 5+\n",
    "        - Algorithms for getting LLMs to use tools\n",
    "    - Agent toolkits: 10+\n",
    "        - Agents armed with specific tools for a specific application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it is now there are six models being covered in Longchain\n",
    "# LLMs and prompts\n",
    "# Chains\n",
    "# Data Augmented Generation\n",
    "# Agents\n",
    "# Memory\n",
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs and Prompts\n",
    "LLMs take a string as an input (prompt) and output a string (completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"text-davinci-003\"\n",
    ")\n",
    "\n",
    "llm_hugging_face = HuggingFaceHub(\n",
    "    repo_id='google/flan-t5-xl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LLM takes a prompt as an input and outputs a completion\n",
    "# prompt = \"My name is Jerry and I am looking for a senior data scientist or machine learning engineer job\"\n",
    "# completion = llm_hugging_face(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 391kB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 95.3kB/s]\n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 5.31MB/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 204kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 38.7kB/s]\n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 9.82MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:01<00:00, 71.1MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 27.0kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 55.9kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 13.3MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 175kB/s]\n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 4.38MB/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 9.82MB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 116kB/s]\n"
     ]
    }
   ],
   "source": [
    "# embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings_hugging_face = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06501688808202744, -0.04788777232170105, 0.051248155534267426, 0.06370953470468521, -0.020586827769875526, -0.13232406973838806, -0.025029074400663376, -0.06336953490972519, -0.07616551220417023, -0.05247809365391731, -0.07098755240440369, -0.03720574080944061, 0.03114102967083454, -0.0573573000729084, -0.034847892820835114, 0.0413450226187706, -0.048038505017757416, -0.01105794683098793, 0.02295728586614132, -0.13795898854732513, 0.01054036058485508, 0.004916073754429817, -0.018240058794617653, -0.11778751015663147, 0.00014174864918459207, -0.00906381756067276, 0.03587860241532326, 0.049300871789455414, 0.0018293778412044048, 0.011244402267038822, -0.04029207304120064, -0.01543509867042303, 0.03291197866201401, 0.10186728835105896, 0.02767772413790226, 0.05389564111828804, -0.05304254591464996, 0.014578720554709435, 0.03618146851658821, 0.04540051147341728, -0.032780278474092484, -0.002884884597733617, -0.07596230506896973, -0.04300385341048241, -0.052731454372406006, 0.02202579937875271, -0.00264448719099164, -0.1396389901638031, 0.09070712327957153, -0.041942719370126724, -0.0980236828327179, -0.045089300721883774, 0.05969260632991791, 0.0019365822663530707, -0.022275486961007118, -0.007549626287072897, 0.06836681813001633, 0.009234198369085789, -0.03556796535849571, 0.0013123820535838604, -0.025660010054707527, -0.02573871612548828, -0.07437139004468918, 0.008057172410190105, -0.015706336125731468, -0.012133573181927204, 0.028306279331445694, 0.08229709416627884, 0.03410656750202179, -0.1837361454963684, -0.020453868433833122, 0.010272076353430748, -0.08614423871040344, 0.0032447201665490866, 0.05517352744936943, -0.021764084696769714, 0.06779200583696365, 0.02197706513106823, 0.12147067487239838, 0.0134851960465312, 0.0076145450584590435, -0.07201262563467026, -0.06792134791612625, 0.045356061309576035, -0.023416949436068535, 0.011865011416375637, -0.07003025710582733, 0.07526055723428726, -0.000688074273057282, -0.043117888271808624, -7.692926010349765e-05, -0.03976646065711975, -0.010320798493921757, 0.024499135091900826, -0.03027907945215702, -0.011983507312834263, 0.00440657464787364, 0.0498310849070549, -0.061809562146663666, 0.030156340450048447, -0.05976938083767891, -0.028667036443948746, 0.06566520035266876, 0.047484252601861954, 0.0152455298230052, 0.08481191843748093, -0.07579459249973297, 0.05765480175614357, 0.011565198190510273, 0.0026701721362769604, -0.02497166581451893, 0.0292319655418396, -0.0580926388502121, 0.0656917542219162, -0.005739786196500063, -0.015354641713202, -0.07778124511241913, 0.034489281475543976, 0.004014858976006508, -0.009981323964893818, -0.04192056134343147, 0.05431178957223892, -0.10532067716121674, 0.028309667482972145, 0.021756108850240707, -0.06135861575603485, -0.06210995465517044, -2.8259409492805815e-33, 0.0439031757414341, 0.0009324733400717378, 0.05406700074672699, -0.019480198621749878, 0.021837439388036728, -0.019782256335020065, -0.020847130566835403, 0.06757233291864395, 0.03303278982639313, 0.014859456568956375, -0.05724364519119263, 0.040010031312704086, -0.043295495212078094, 0.035258322954177856, -0.09836220741271973, 0.024630442261695862, 0.0004772153915837407, 0.0013256208039820194, -0.10985062271356583, 0.040428388863801956, 0.017443032935261726, -0.06903164833784103, -0.026144955307245255, 0.04219334200024605, -0.022618841379880905, 0.010059433989226818, -0.017695238813757896, -0.037207312881946564, 0.10963460803031921, 0.037469666451215744, -0.023983199149370193, -0.02423936501145363, -0.0018299848306924105, 0.011569665744900703, 0.058344848453998566, 0.007742159999907017, -0.027009589597582817, -0.03278525546193123, 0.020292894914746284, 0.026711709797382355, -0.013516034930944443, 0.04240681976079941, 0.05167117342352867, -0.004911947995424271, -0.027818400412797928, -0.049556855112314224, 0.11178914457559586, -0.05452686548233032, 0.12761175632476807, 0.026305826380848885, -0.07418466359376907, -0.020089346915483475, 0.006358471233397722, 0.0006247590645216405, -0.0014145586173981428, 0.04150225222110748, 0.07378443330526352, -0.00619652820751071, 0.008873595856130123, 0.07933005690574646, -0.08905015140771866, 0.07566255331039429, -0.03127184137701988, 0.019390741363167763, -0.014436638914048672, -0.03725384175777435, 0.052267979830503464, -0.008799062110483646, 0.055788084864616394, 0.07739084213972092, 0.04309955984354019, -0.008337886072695255, 0.11464429646730423, 0.026579922065138817, 0.06280818581581116, 0.021330449730157852, -0.02098357491195202, -0.054622236639261246, 0.019991034641861916, 0.005100575275719166, 0.07054760307073593, -0.023911142721772194, 0.0017720501637086272, 0.02901630848646164, 0.11136165261268616, 0.06430884450674057, -0.03774719312787056, -0.033890414983034134, -0.002668441040441394, 0.011199883185327053, -0.10930721461772919, -0.01592094451189041, 0.05206013470888138, 0.03959853947162628, -0.025119727477431297, -1.1095763928835161e-33, -0.04085777699947357, 0.011771902441978455, 0.022526828572154045, 0.06094017252326012, 0.09378871321678162, 0.0058002169243991375, 0.07802128791809082, -0.026897354051470757, 0.047427356243133545, 0.004615278914570808, -0.00528442719951272, 0.009093684144318104, 0.007659397087991238, 0.010143681429326534, -0.010373730212450027, 0.10493206232786179, -0.09413179010152817, 0.02492520585656166, -0.13026924431324005, -0.024147525429725647, -0.045892953872680664, 0.10029539465904236, -0.11607344448566437, 0.0424344576895237, 0.0800890401005745, -0.058107197284698486, 0.007757697254419327, 0.014448623172938824, -0.00844950694590807, 0.07177330553531647, -0.09867145121097565, -0.004462967626750469, -0.04805124178528786, -0.015794899314641953, -0.041502080857753754, -0.03667960315942764, 0.019231989979743958, 0.006847722455859184, -0.01891089789569378, 0.015064320527017117, -0.014064975082874298, -0.06557465344667435, -0.0050200228579342365, -0.03158002719283104, -0.015582723543047905, -0.006110129877924919, 0.0066884052939713, 0.048264030367136, 0.007184804417192936, -0.07269550859928131, 0.012314964085817337, 0.06752266734838486, 0.0369388684630394, -0.02807936817407608, 0.03149860352277756, 0.03111545741558075, 0.05501444637775421, -0.008591018617153168, -0.09005022048950195, -0.02949398010969162, -0.00730098458006978, 0.0077128056436777115, 0.09922753274440765, 0.059822969138622284, 0.018744584172964096, 0.04598494619131088, 0.0585513673722744, 0.0223399605602026, -0.10259361565113068, -0.06040562689304352, 0.10926660150289536, 0.0284910649061203, 0.030670657753944397, -0.015135136432945728, -0.05035930499434471, -0.027013787999749184, -0.07618562132120132, -0.011630327440798283, -0.05206133797764778, 0.09954787790775299, 0.020263245329260826, -0.030589189380407333, -0.01288579311221838, 0.06900955736637115, -0.025277864187955856, 0.0441678985953331, -0.0011802923399955034, -0.006697455886751413, -0.025180771946907043, -0.09850320965051651, -0.05592953786253929, -1.949635952769313e-05, -0.05033240467309952, -0.019515421241521835, 0.0018537082942202687, -2.047430847085252e-08, 0.006107466295361519, 0.012914673425257206, 0.008927502669394016, -0.08149203658103943, 0.03614788502454758, 0.02475021593272686, -0.03178869187831879, 0.03165721893310547, -0.013605521060526371, -0.025946199893951416, 0.05253973230719566, 0.041078805923461914, 0.03368184715509415, -0.03237762302160263, 0.06341931223869324, -0.057850178331136703, 0.023467937484383583, -0.005448203068226576, -0.005410296842455864, -0.002577647566795349, 0.012015728279948235, 0.039440203458070755, 0.010188020765781403, 0.054807212203741074, 0.011527790687978268, 0.0015425708843395114, -0.018151244148612022, 0.03664489462971687, -0.07301980257034302, -0.0360662080347538, -0.06600602716207504, 0.05265358090400696, 0.0027339544612914324, -0.04311543330550194, 0.1267237812280655, -0.08962588012218475, 0.11519454419612885, -0.029792891815304756, -0.029274655506014824, -0.024018006399273872, -0.04484812915325165, 0.03349068760871887, -0.014972776174545288, 0.024420270696282387, 0.04406357184052467, 0.09966620802879333, 0.018153676763176918, -0.025939803570508957, 0.030217649415135384, 0.011330456472933292, 0.07043527066707611, 0.034331779927015305, -0.022376012057065964, 0.04512613266706467, 0.01514021959155798, 0.0056885951198637486, -0.058902084827423096, -0.09230973571538925, -0.09563400596380234, -0.0036592334508895874, 0.08867210149765015, -0.0540606714785099, 0.018345873802900314, -0.01648210734128952]\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "# The embeddings model takes a text as an input and outputs a list of floats\n",
    "text = \"My name is Jerry and I am looking for a senior data scientist or machine learning engineer job\"\n",
    "text_embedding = embeddings_hugging_face.embed_query(text)\n",
    "\n",
    "print(text_embedding)\n",
    "print(len(text_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models, Prompts and Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# Load API credentials\n",
    "with open('api_key.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "os.environ['OPENAI_API_KEY'] = config['OPEN_AI_KEY']\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = config['HUGGING_FACE_TOKEN_KEY']\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model = \"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = 0.5\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI stands for Artificial Intelligence. It refers to the development of computer systems or machines that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and problem-solving. AI aims to create intelligent machines that can learn, reason, and adapt to new situations, ultimately mimicking or augmenting human intelligence. AI can be categorized into two types: narrow AI, which is designed for specific tasks, and general AI, which has the ability to understand, learn, and apply knowledge across various domains.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_1 = \"\"\"\n",
    "I am really sad that people are facing massive layoffs... \\\n",
    "The same situation may happen to me as well. \\\n",
    "The best you can do is to stay positive and work hard!!! \\\n",
    "The future will be better!!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"\n",
    "Canada English \\ \n",
    "into a positive tone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the text that is delimited by triple backticks\n",
    "into a style that is {style}.\n",
    "text: '''{paragraph_1}'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translate the text that is delimited by triple backticks\n",
      "into a style that is \n",
      "Canada English \\ \n",
      "into a positive tone\n",
      ".\n",
      "text: '''\n",
      "I am really sad that people are facing massive layoffs... The same situation may happen to me as well. The best you can do is to stay positive and work hard!!! The future will be better!!!\n",
      "'''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt=prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.3, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # model\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt (template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# this template_1 is a translate template\n",
    "template_1 = \"\"\"\n",
    "translate the text that in delimiated by double quos into a style that is {style}. \\\n",
    "text: \"{text}\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    template = template_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed the input string with 1) text 2) style into the prompt template\n",
    "paragraph_1 = \"\"\"\n",
    "I really hate school!!! \\\n",
    "I want to fk you all off, school sucks!!! \\\n",
    "\"\"\"\n",
    "style = \"\"\"\n",
    "English \\\n",
    "in a rude and disrespectful tone\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_msg = prompt_template.format_messages(\n",
    "    style = style,\n",
    "    text = paragraph_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_response = chat(prompt_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I absolutely despise school!!! I couldn't care less about any of you, school is absolutely garbage!!!\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the content back\n",
    "prompt_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse (can treat it as the reverse of prompt, to extract the key information from the paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use case\n",
    "# to parse the review/comment with parse template to extract the key entity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
